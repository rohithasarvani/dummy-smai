{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5aeceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 – Imports, Setup & Utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Directory setup\n",
    "IMG_DIR = \"/home/rohitha/ass3\"\n",
    "\n",
    "def create_coord_grid(h, w):\n",
    "    \"\"\"\n",
    "    Create a normalized 2D coordinate grid in [-1, 1]^2.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    h, w : int\n",
    "        Height and width of the image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coords : np.ndarray\n",
    "        Array of shape (h*w, 2), each row is [x, y].\n",
    "    \"\"\"\n",
    "    ys, xs = np.linspace(-1, 1, h), np.linspace(-1, 1, w)\n",
    "    grid_x, grid_y = np.meshgrid(xs, ys)\n",
    "    coords = np.stack([grid_x, grid_y], axis=-1).reshape(-1, 2)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def load_image(path, mode=\"L\", size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load and resize image from given path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to image.\n",
    "    mode : str\n",
    "        'L' for grayscale or 'RGB' for color.\n",
    "    size : tuple\n",
    "        Desired image size.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Image array normalized to [0, 1].\n",
    "    \"\"\"\n",
    "    img = PILImage.open(path).convert(mode).resize(size)\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957497f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 – Feature Mapping Classes\n",
    "import numpy as np\n",
    "\n",
    "class BaseFeatureMapping:\n",
    "    \"\"\"Abstract base class for all feature mappings.\"\"\"\n",
    "\n",
    "    def transform(self, coords: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transform input coordinates into mapped features.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement transform().\")\n",
    "\n",
    "\n",
    "class RawMapping(BaseFeatureMapping):\n",
    "    \"\"\"Raw coordinate mapping: γ_raw(x, y) = (x, y)\"\"\"\n",
    "\n",
    "    def transform(self, coords: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Use raw (x, y) coordinates as features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        coords : np.ndarray\n",
    "            Normalized coordinates (N, 2).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Same as input (N, 2).\n",
    "        \"\"\"\n",
    "        return coords\n",
    "\n",
    "\n",
    "class PolynomialMapping(BaseFeatureMapping):\n",
    "    \"\"\"Polynomial expansion (Taylor-inspired) up to a given order.\"\"\"\n",
    "\n",
    "    def __init__(self, order: int = 5):\n",
    "        self.order = order\n",
    "\n",
    "    def transform(self, coords: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Expand coordinates into polynomial terms:\n",
    "        [x, y, x², y², xy, ..., x^k, y^k].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        coords : np.ndarray\n",
    "            Normalized coordinates (N, 2).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Expanded feature matrix (N, D).\n",
    "        \"\"\"\n",
    "        x, y = coords[:, 0], coords[:, 1]\n",
    "        features = [x, y]\n",
    "\n",
    "        for i in range(2, self.order + 1):\n",
    "            features += [x ** i, y ** i, (x * y) ** (i - 1)]\n",
    "\n",
    "        return np.stack(features, axis=1)\n",
    "\n",
    "\n",
    "class FourierMapping(BaseFeatureMapping):\n",
    "    \"\"\"Fourier feature mapping using sin/cos embeddings.\"\"\"\n",
    "\n",
    "    def __init__(self, freq: int = 10):\n",
    "        self.freq = freq\n",
    "\n",
    "    def transform(self, coords: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply Fourier mapping to coordinates:\n",
    "        [1, sin(2πfx), cos(2πfx), sin(2πfy), cos(2πfy)] for f = 1...k\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        coords : np.ndarray\n",
    "            Normalized coordinates (N, 2).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Fourier-encoded features (N, D).\n",
    "        \"\"\"\n",
    "        x, y = coords[:, 0], coords[:, 1]\n",
    "        features = [np.ones_like(x)]  # bias term\n",
    "\n",
    "        for f in range(1, self.freq + 1):\n",
    "            features += [\n",
    "                np.sin(2 * np.pi * f * x),\n",
    "                np.cos(2 * np.pi * f * x),\n",
    "                np.sin(2 * np.pi * f * y),\n",
    "                np.cos(2 * np.pi * f * y),\n",
    "            ]\n",
    "\n",
    "        return np.stack(features, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 – Normalization Utilities\n",
    "def normalize_features(features: np.ndarray, method: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize feature vectors according to the mapping type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.ndarray\n",
    "        Input features (N, D).\n",
    "    method : str\n",
    "        'Raw', 'Polynomial', or 'Fourier'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Normalized feature matrix (N, D).\n",
    "    \"\"\"\n",
    "    method = method.lower()\n",
    "\n",
    "    if method == \"raw\":\n",
    "        normed = (features + 1.0) / 2.0  # scale from [-1, 1] to [0, 1]\n",
    "\n",
    "    elif method == \"polynomial\":\n",
    "        mean = np.mean(features, axis=0, keepdims=True)\n",
    "        std = np.std(features, axis=0, keepdims=True) + 1e-8\n",
    "        normed = np.clip((features - mean) / std, -3, 3)\n",
    "\n",
    "    elif method == \"fourier\":\n",
    "        normed = features  # already bounded in [-1, 1]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    return normed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 – Modular DataLoader\n",
    "class ModularDataloader:\n",
    "    \"\"\"\n",
    "    Modular dataloader for preparing image reconstruction datasets\n",
    "    with different feature mappings (Raw / Polynomial / Fourier).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_path, image_type=\"Gray\", method=\"Raw\", order=5, freq=10):\n",
    "        \"\"\"\n",
    "        Initialize the dataloader.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img_path : str\n",
    "            Path to the image file.\n",
    "        image_type : str\n",
    "            'Gray' or 'RGB'.\n",
    "        method : str\n",
    "            Feature mapping type ('Raw', 'Polynomial', 'Fourier').\n",
    "        order : int\n",
    "            Order of polynomial expansion (for 'Polynomial').\n",
    "        freq : int\n",
    "            Number of Fourier frequencies (for 'Fourier').\n",
    "        \"\"\"\n",
    "        self.img_path = img_path\n",
    "        self.image_type = image_type\n",
    "        self.method = method\n",
    "        self.order = order\n",
    "        self.freq = freq\n",
    "\n",
    "        # Step 1: Load image\n",
    "        mode = \"L\" if image_type.lower() == \"gray\" else \"RGB\"\n",
    "        self.img = load_image(img_path, mode=mode, size=(256, 256))\n",
    "\n",
    "        # Step 2: Create coordinate grid\n",
    "        h, w = self.img.shape[:2]\n",
    "        self.coords = create_coord_grid(h, w)\n",
    "\n",
    "        # Step 3: Select feature mapper\n",
    "        if method == \"Raw\":\n",
    "            self.mapper = RawMapping()\n",
    "        elif method == \"Polynomial\":\n",
    "            self.mapper = PolynomialMapping(order=order)\n",
    "        elif method == \"Fourier\":\n",
    "            self.mapper = FourierMapping(freq=freq)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid method. Choose Raw / Polynomial / Fourier.\")\n",
    "\n",
    "        # Step 4: Apply mapping\n",
    "        raw_features = self.mapper.transform(self.coords)\n",
    "\n",
    "        # Step 5: Normalize features\n",
    "        self.features = normalize_features(raw_features, method)\n",
    "\n",
    "        # Step 6: Prepare target pixels\n",
    "        self.targets = (\n",
    "            self.img.reshape(-1, 1)\n",
    "            if image_type.lower() == \"gray\"\n",
    "            else self.img.reshape(-1, 3)\n",
    "        )\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Returns normalized input features and pixel targets.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : np.ndarray\n",
    "            Normalized input features (N, D)\n",
    "        y : np.ndarray\n",
    "            Target pixel values (N, C)\n",
    "        \"\"\"\n",
    "        return self.features, self.targets\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"Print dataset details.\"\"\"\n",
    "        print(f\"Image: {os.path.basename(self.img_path)}\")\n",
    "        print(f\"Type: {self.image_type}\")\n",
    "        print(f\"Mapping: {self.method}\")\n",
    "        print(f\"Feature Dimension: {self.features.shape[1]}\")\n",
    "        print(f\"Total Pixels: {self.features.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 – Visualization Helpers\n",
    "def visualize_feature_mapping(mapping, coords, title=\"Feature Mapping\", n_features=3):\n",
    "    \"\"\"\n",
    "    Visualize the first few dimensions of a transformed feature space.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapping : BaseFeatureMapping\n",
    "        Instance of RawMapping, PolynomialMapping, or FourierMapping.\n",
    "    coords : np.ndarray\n",
    "        Normalized coordinates (N, 2).\n",
    "    title : str\n",
    "        Plot title.\n",
    "    n_features : int\n",
    "        Number of feature dimensions to visualize.\n",
    "    \"\"\"\n",
    "    transformed = mapping.transform(coords)\n",
    "    h = w = int(np.sqrt(coords.shape[0]))\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    for i in range(min(n_features, transformed.shape[1])):\n",
    "        plt.subplot(1, n_features, i + 1)\n",
    "        plt.imshow(transformed[:, i].reshape(h, w), cmap=\"viridis\")\n",
    "        plt.title(f\"{title}\\nFeature {i+1}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90101168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 – Test Dataloader and Visualizations\n",
    "# Image paths\n",
    "smiley_path = os.path.join(IMG_DIR, \"smiley.png\")\n",
    "cat_path = os.path.join(IMG_DIR, \"cat.jpg\")\n",
    "\n",
    "# Initialize dataloaders\n",
    "gray_loader = ModularDataloader(smiley_path, \"Gray\", \"Polynomial\", order=5)\n",
    "rgb_loader = ModularDataloader(cat_path, \"RGB\", \"Fourier\", freq=10)\n",
    "\n",
    "# Print summaries\n",
    "gray_loader.summary()\n",
    "rgb_loader.summary()\n",
    "\n",
    "# Visualize targets\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray_loader.targets.reshape(256, 256), cmap=\"gray\")\n",
    "plt.title(\"Grayscale Target Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(rgb_loader.targets.reshape(256, 256, 3))\n",
    "plt.title(\"RGB Target Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature mappings\n",
    "coords = create_coord_grid(256, 256)\n",
    "visualize_feature_mapping(RawMapping(), coords, \"Raw Mapping\", 2)\n",
    "visualize_feature_mapping(PolynomialMapping(order=5), coords, \"Polynomial Mapping\", 3)\n",
    "visualize_feature_mapping(FourierMapping(freq=10), coords, \"Fourier Mapping\", 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ba28c",
   "metadata": {},
   "source": [
    "# Imported from 1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c28dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"ReLU Activation\"\"\"\n",
    "    def forward(self, x):\n",
    "        self.out = np.maximum(0, x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = grad_output * (self.out > 0)\n",
    "        return grad_input\n",
    "\n",
    "class Tanh:\n",
    "    \"\"\"Tanh Activation\"\"\"\n",
    "    def forward(self, x):\n",
    "        self.out = np.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = grad_output * (1 - self.out**2)\n",
    "        return grad_input\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"Sigmoid Activation\"\"\"\n",
    "    def forward(self, x):\n",
    "        self.out = 1 / (1 + np.exp(-x))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = grad_output * self.out * (1 - self.out)\n",
    "        return grad_input\n",
    "\n",
    "class Identity:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output\n",
    "\n",
    "    def update(self, lr):\n",
    "        pass\n",
    "\n",
    "    def zero_grad(self):\n",
    "        pass  # nothing to reset, but must exist for consistency\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Identity()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d792eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \"\"\"Fully Connected Layer\"\"\"\n",
    "    def __init__(self, in_features, out_features, activation):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.activation = activation\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.randn(in_features, out_features) * np.sqrt(2.0 / in_features)\n",
    "        self.b = np.zeros((1, out_features))\n",
    "\n",
    "        # Cumulative gradients\n",
    "        self.dW_cum = np.zeros_like(self.W)\n",
    "        self.db_cum = np.zeros_like(self.b)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x  # Save for backward\n",
    "        self.linear_out = x @ self.W + self.b\n",
    "        self.out = self.activation.forward(self.linear_out)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        # Gradient w.r.t activation\n",
    "        grad_activation = self.activation.backward(grad_output)\n",
    "        # Gradients w.r.t weights and biases\n",
    "        self.dW_cum += self.input.T @ grad_activation\n",
    "        self.db_cum += np.sum(grad_activation, axis=0, keepdims=True)\n",
    "        # Gradient w.r.t input for previous layer\n",
    "        grad_input = grad_activation @ self.W.T\n",
    "        return grad_input\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.dW_cum.fill(0)\n",
    "        self.db_cum.fill(0)\n",
    "\n",
    "    def update(self, lr=0.01):\n",
    "        self.W -= lr * self.dW_cum\n",
    "        self.b -= lr * self.db_cum\n",
    "        self.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"Neural Network Model\"\"\"\n",
    "    def __init__(self, layers, loss_type=\"MSE\"):\n",
    "        self.layers = layers\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "\n",
    "    def backward(self, grad):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "\n",
    "    def train(self, x, y):\n",
    "        \"\"\"Forward + backward pass, returns scalar loss\"\"\"\n",
    "        y_pred = self.forward(x)\n",
    "        # Compute loss\n",
    "        if self.loss_type == \"MSE\":\n",
    "            loss = np.mean((y_pred - y) ** 2)\n",
    "            grad_loss = 2 * (y_pred - y) / y.shape[0]\n",
    "        elif self.loss_type == \"BCE\":\n",
    "            eps = 1e-9\n",
    "            y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "            loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "            grad_loss = (y_pred - y) / (y_pred * (1 - y_pred)) / y.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Unknown loss type\")\n",
    "\n",
    "        self.backward(grad_loss)\n",
    "        return float(loss)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for layer in self.layers:\n",
    "            layer.zero_grad()\n",
    "\n",
    "    def update(self, lr=0.01):\n",
    "        for layer in self.layers:\n",
    "            layer.update(lr=lr)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def save_to(self, path):\n",
    "        data = {}\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            # only save layers that have weights\n",
    "            if hasattr(layer, \"W\") and hasattr(layer, \"b\"):\n",
    "                data[f\"W_{idx}\"] = layer.W\n",
    "                data[f\"b_{idx}\"] = layer.b\n",
    "        np.savez(path, **data)\n",
    "\n",
    "    def load_from(self, path):\n",
    "        loaded = np.load(path)\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            w_key = f\"W_{idx}\"\n",
    "            b_key = f\"b_{idx}\"\n",
    "            if w_key not in loaded or b_key not in loaded:\n",
    "                raise ValueError(\"Architecture mismatch!\")\n",
    "            if layer.W.shape != loaded[w_key].shape or layer.b.shape != loaded[b_key].shape:\n",
    "                raise ValueError(\"Shape mismatch!\")\n",
    "            layer.W = loaded[w_key]\n",
    "            layer.b = loaded[b_key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e813170",
   "metadata": {},
   "source": [
    "# 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "import imageio\n",
    "\n",
    "# Assume the previous helper classes (Linear, ReLU, Sigmoid, Model, Modular_Dataloader)\n",
    "# are defined in a separate file or a previous cell.\n",
    "\n",
    "# --- Configuration ---\n",
    "# Create a directory to save images, GIFs, and results\n",
    "IMG_DIR = \"training_results\"\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "# Define paths to the images\n",
    "smiley_path = \"smiley.png\"\n",
    "cat_path = \"cat.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim, hidden_sizes=[64, 128, 128]):\n",
    "    \"\"\"\n",
    "    Creates a 3-layer MLP model with a consistent architecture.\n",
    "    \n",
    "    This function directly supports the assignment's requirement to use the\n",
    "    same MLP architecture for all methods to ensure a fair comparison.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): The number of input features. This changes based\n",
    "                         on the feature mapping (Raw, Poly, Fourier).\n",
    "        output_dim (int): The number of output values (1 for grayscale, 3 for RGB).\n",
    "        hidden_sizes (list): A list of integers for the sizes of hidden layers.\n",
    "\n",
    "    Returns:\n",
    "        Model: An instance of the MLP model.\n",
    "    \"\"\"\n",
    "    layers = [\n",
    "        Linear(input_dim, hidden_sizes[0], ReLU()),\n",
    "        Linear(hidden_sizes[0], hidden_sizes[1], ReLU()),\n",
    "        Linear(hidden_sizes[1], hidden_sizes[2], ReLU()),\n",
    "        Linear(hidden_sizes[2], output_dim, Sigmoid())\n",
    "    ]\n",
    "    return Model(layers, loss_type=\"MSE\")\n",
    "\n",
    "def train_and_save_epochs(model, X_train, y_train, num_epochs, img_shape, save_dir, batch_size=256, lr=0.1):\n",
    "    \"\"\"\n",
    "    Trains the model and saves the reconstructed image at each epoch.\n",
    "    \n",
    "    This function fulfills the core training requirement. It saves the output\n",
    "    image from each epoch, which is necessary for creating the final comparison GIF.\n",
    "\n",
    "    Args:\n",
    "        model (Model): The MLP model to be trained.\n",
    "        X_train (np.ndarray): The input training data (features).\n",
    "        y_train (np.ndarray): The target training data (pixel values).\n",
    "        num_epochs (int): The total number of epochs for training.\n",
    "        img_shape (tuple): The shape of the output image (e.g., (H, W) or (H, W, C)).\n",
    "        save_dir (str): The directory where epoch images will be saved.\n",
    "        batch_size (int): The size of each training batch.\n",
    "        lr (float): The learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list: The history of average loss per epoch.\n",
    "            - list: The history of time taken per epoch.\n",
    "            - float: The final inference loss on the full dataset.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    num_samples = X_train.shape[0]\n",
    "    loss_history = []\n",
    "    epoch_times = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Shuffle data for each epoch\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        X_shuffled, y_shuffled = X_train[indices], y_train[indices]\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        num_batches = int(np.ceil(num_samples / batch_size))\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            X_batch, y_batch = X_shuffled[i:i+batch_size], y_shuffled[i:i+batch_size]\n",
    "            batch_loss = model.train(X_batch, y_batch)\n",
    "            model.update(lr=lr)\n",
    "            epoch_loss += batch_loss\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        loss_history.append(avg_loss)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Save the reconstructed image for this epoch\n",
    "        y_pred = model.predict(X_train)\n",
    "        img_recon = np.clip(y_pred.reshape(img_shape), 0, 1)\n",
    "        img_save = (img_recon * 255).astype(np.uint8)\n",
    "        \n",
    "        mode = 'L' if len(img_shape) == 2 else 'RGB'\n",
    "        PILImage.fromarray(img_save, mode=mode).save(os.path.join(save_dir, f'epoch_{epoch:03d}.png'))\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}, Time: {epoch_time:.2f}s\")\n",
    "            \n",
    "    final_loss = np.mean((model.predict(X_train) - y_train) ** 2)\n",
    "    return loss_history, epoch_times, final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Configuration ---\n",
    "training_configs = {\n",
    "    \"smiley\": {\"path\": smiley_path, \"epochs\": 50, \"shape\": (256, 256), \"type\": \"Gray\", \"output_dim\": 1},\n",
    "    \"cat\": {\"path\": cat_path, \"epochs\": 150, \"shape\": (256, 256, 3), \"type\": \"RGB\", \"output_dim\": 3}\n",
    "}\n",
    "feature_configs = {\n",
    "    \"Raw\": [{}],\n",
    "    \"Polynomial\": [{\"order\": o} for o in [5, 15, 25]],\n",
    "    \"Fourier\": [{\"freq\": f} for f in [5, 15, 25]]\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "saved_data = {} # To store loss histories and save directories for GIF creation\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "for img_name, img_conf in training_configs.items():\n",
    "    print(f\"\\n{'='*80}\\nTRAINING ON {img_name.upper()} IMAGE\\n{'='*80}\")\n",
    "    saved_data[img_name] = {}\n",
    "    \n",
    "    for method, params_list in feature_configs.items():\n",
    "        for params in params_list:\n",
    "            param_str = \", \".join([f\"{k}={v}\" for k, v in params.items()])\n",
    "            print(f\"\\n--- Training with {method} Features ({param_str or 'Baseline'}) ---\")\n",
    "            \n",
    "            # 1. Load Data\n",
    "            loader = ModularDataloader(img_path=img_conf[\"path\"], image_type=img_conf[\"type\"], method=method, **params)\n",
    "            X_train, y_train = loader.get_data()\n",
    "            \n",
    "            # 2. Create Model\n",
    "            model = create_model(input_dim=X_train.shape[1], output_dim=img_conf[\"output_dim\"])\n",
    "            \n",
    "            # 3. Train Model\n",
    "            save_dir_name = f\"results_{img_name}_{method.lower()}\" + \"\".join([f\"_{v}\" for v in params.values()])\n",
    "            save_dir = os.path.join(IMG_DIR, save_dir_name)\n",
    "            \n",
    "            loss_hist, time_hist, final_loss = train_and_save_epochs(\n",
    "                model, X_train, y_train,\n",
    "                num_epochs=img_conf[\"epochs\"],\n",
    "                img_shape=img_conf[\"shape\"],\n",
    "                save_dir=save_dir\n",
    "            )\n",
    "            \n",
    "            # 4. Store Results\n",
    "            result = {\n",
    "                'Image': img_name.capitalize(),\n",
    "                'Method': method,\n",
    "                'Parameters': param_str or '-',\n",
    "                'Final Loss': final_loss,\n",
    "                'Avg Epoch Time (s)': np.mean(time_hist),\n",
    "                'Input Dimensions': X_train.shape[1]\n",
    "            }\n",
    "            all_results.append(result)\n",
    "            \n",
    "            # Save data needed for GIF\n",
    "            key = f\"{method}_{param_str}\" if params else method\n",
    "            saved_data[img_name][key] = {'loss_history': loss_hist, 'save_dir': save_dir}\n",
    "\n",
    "            print(f\"Final Loss: {final_loss:.6f}, Avg Epoch Time: {np.mean(time_hist):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the collected results\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Display table for Smiley\n",
    "print(f\"\\n{'='*80}\\nRESULTS TABLE - SMILEY IMAGE\\n{'='*80}\")\n",
    "df_smiley = df_results[df_results['Image'] == 'Smiley'].drop(columns='Image')\n",
    "print(df_smiley.to_string(index=False))\n",
    "df_smiley.to_csv(os.path.join(IMG_DIR, 'results_smiley.csv'), index=False)\n",
    "\n",
    "# Display table for Cat\n",
    "print(f\"\\n{'='*80}\\nRESULTS TABLE - CAT IMAGE\\n{'='*80}\")\n",
    "df_cat = df_results[df_results['Image'] == 'Cat'].drop(columns='Image')\n",
    "print(df_cat.to_string(index=False))\n",
    "df_cat.to_csv(os.path.join(IMG_DIR, 'results_cat.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb386dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_gif(raw_data, poly_data, fourier_data, poly_label, fourier_label, num_epochs, output_path, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Creates a 1x3 subplot GIF comparing Raw, Polynomial, and Fourier methods.\n",
    "    \n",
    "    This function directly addresses the visualization requirement by generating\n",
    "    a GIF that includes a legend in each subplot showing the live loss curve.\n",
    "\n",
    "    Args:\n",
    "        raw_data (dict): Dict with 'loss_history' and 'save_dir' for Raw features.\n",
    "        poly_data (dict): Dict for the chosen Polynomial features.\n",
    "        fourier_data (dict): Dict for the chosen Fourier features.\n",
    "        poly_label (str): Label for the Polynomial subplot (e.g., \"Poly (Order=15)\").\n",
    "        fourier_label (str): Label for the Fourier subplot (e.g., \"Fourier (Freq=15)\").\n",
    "        num_epochs (int): The total number of epochs (frames in the GIF).\n",
    "        output_path (str): The file path to save the generated GIF.\n",
    "        title_prefix (str): A prefix for the main GIF title (e.g., \"Smiley\").\n",
    "    \"\"\"\n",
    "    gif_frames = []\n",
    "    all_losses = raw_data['loss_history'] + poly_data['loss_history'] + fourier_data['loss_history']\n",
    "    min_loss, max_loss = np.min(all_losses), np.max(all_losses)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6.5))\n",
    "        fig.suptitle(f'{title_prefix} Reconstruction Comparison (Epoch {epoch+1}/{num_epochs})', fontsize=16)\n",
    "\n",
    "        # --- Data for the 3 subplots ---\n",
    "        plot_data = [\n",
    "            {'title': 'Raw Features', 'data': raw_data},\n",
    "            {'title': poly_label, 'data': poly_data},\n",
    "            {'title': fourier_label, 'data': fourier_data},\n",
    "        ]\n",
    "\n",
    "        for i, p in enumerate(plot_data):\n",
    "            # Load the main image\n",
    "            img_path = os.path.join(p['data']['save_dir'], f'epoch_{epoch:03d}.png')\n",
    "            img = PILImage.open(img_path)\n",
    "            axes[i].imshow(img, cmap='gray' if img.mode == 'L' else None)\n",
    "            axes[i].set_title(f\"{p['title']}\\nLoss: {p['data']['loss_history'][epoch]:.5f}\", fontsize=12)\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "            # --- Add inset plot for the loss curve ---\n",
    "            ax_inset = axes[i].inset_axes([0.05, 0.05, 0.35, 0.25], facecolor='w', alpha=0.8)\n",
    "            ax_inset.plot(range(epoch + 1), p['data']['loss_history'][:epoch + 1], color='b')\n",
    "            ax_inset.set_yscale('log')\n",
    "            ax_inset.set_ylim(min_loss, max_loss) # Consistent y-axis\n",
    "            ax_inset.set_title(\"Loss Curve\", fontsize=8)\n",
    "            ax_inset.tick_params(axis='both', which='major', labelsize=7)\n",
    "            ax_inset.grid(True, alpha=0.4)\n",
    "            \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        \n",
    "        # Convert plot to an image array for the GIF\n",
    "        fig.canvas.draw()\n",
    "        frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        gif_frames.append(frame)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Save the frames as a GIF\n",
    "    imageio.mimsave(output_path, gif_frames, fps=5, loop=0)\n",
    "    print(f\"GIF saved successfully to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f49eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPyImage, display\n",
    "\n",
    "# --- Choose one combination of features for the GIF ---\n",
    "# We'll pick the mid-range parameters for a representative comparison.\n",
    "POLY_ORDER_GIF = 15\n",
    "FOURIER_FREQ_GIF = 15\n",
    "\n",
    "# --- Generate Smiley GIF ---\n",
    "print(\"\\nCreating GIF for SMILEY image comparison...\")\n",
    "smiley_gif_path = os.path.join(IMG_DIR, 'smiley_comparison.gif')\n",
    "create_comparison_gif(\n",
    "    raw_data=saved_data['smiley']['Raw'],\n",
    "    poly_data=saved_data['smiley'][f'Polynomial_order={POLY_ORDER_GIF}'],\n",
    "    fourier_data=saved_data['smiley'][f'Fourier_freq={FOURIER_FREQ_GIF}'],\n",
    "    poly_label=f'Polynomial (Order={POLY_ORDER_GIF})',\n",
    "    fourier_label=f'Fourier (Freq={FOURIER_FREQ_GIF})',\n",
    "    num_epochs=training_configs['smiley']['epochs'],\n",
    "    output_path=smiley_gif_path,\n",
    "    title_prefix=\"Smiley\"\n",
    ")\n",
    "display(IPyImage(filename=smiley_gif_path))\n",
    "\n",
    "\n",
    "# --- Generate Cat GIF ---\n",
    "print(\"\\nCreating GIF for CAT image comparison...\")\n",
    "cat_gif_path = os.path.join(IMG_DIR, 'cat_comparison.gif')\n",
    "create_comparison_gif(\n",
    "    raw_data=saved_data['cat']['Raw'],\n",
    "    poly_data=saved_data['cat'][f'Polynomial_order={POLY_ORDER_GIF}'],\n",
    "    fourier_data=saved_data['cat'][f'Fourier_freq={FOURIER_FREQ_GIF}'],\n",
    "    poly_label=f'Polynomial (Order={POLY_ORDER_GIF})',\n",
    "    fourier_label=f'Fourier (Freq={FOURIER_FREQ_GIF})',\n",
    "    num_epochs=training_configs['cat']['epochs'],\n",
    "    output_path=cat_gif_path,\n",
    "    title_prefix=\"Cat\"\n",
    ")\n",
    "display(IPyImage(filename=cat_gif_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
